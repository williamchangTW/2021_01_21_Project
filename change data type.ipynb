{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# TODO: ckpt.py file content has some error, may produce too many files but it can not got any one before use\\n# need to check design is correct\\n# training test when checkpoint is added\\nimport sys, subprocess, os, signal\\n#import platform components\\nimport numpy as np\\n#import tensorflow as tf\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Conv2D, AveragePooling2D, Flatten\\nfrom tensorflow.keras.layers import MaxPooling2D\\nfrom tensorflow.keras.optimizers import Adam\\nfrom csv_loader import dy_checkpoint, csv_loader\\nfrom file_correctness import correct_model, correct_data, clear_path, correctness\\nfrom checkpoint import ckpt, ckpt_create\\nfrom recover_system_status import rss_initial, rss\\n#from environment_detector import envir_daemon, start_daemon, env_initial\\n#import custckpt\\n\\ndef datapreprocess(data_train, x_test):\\n    n_samples_test = x_test.shape[0]\\n    y_train = np.array(data_train[:, 0])\\n    x_train = np.array(data_train[:, 1:])\\n    y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)\\n    return x_train, y_train\\n\\n\\n# make sure process is not duplicate\\npid = os.getpid()\\nwith open(\"train_pid.txt\", \"w\") as wf:\\n\\twf.write(\"tradinPID: \" + str(pid) + \"\\n\")\\n\\twf.close()\\n# recieve user input and run file correctness check\\n# start to read user input\\n# dynamic loader\\ntrain = csv_loader.CSVLoader(\"./data/cor/train.csv\")._dynamic_allocate()\\ntest = csv_loader.CSVLoader(\"./data/cor/test.csv\")._dynamic_allocate()\\ntrain, test = datapreprocess(train, test)\\n# model part\\n# test comment\\n# test comment\\n#testtemp\\nmodel = Sequential()\\nmodel.add(Reshape(target_shape=(1, 28, 28), input_shape=(784,)))\\nmodel.add(Conv2D(kernel_size=(3, 3), filters=6, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\\nmodel.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\\nmodel.add(Conv2D(kernel_size=(5, 5), filters=16, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\\nmodel.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\\nmodel.add(Conv2D(kernel_size=(5, 5), filters=120, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\\nmodel.add(Flatten())\\nmodel.add(Dense(120, activation=\\'relu\\'))\\nmodel.add(Dense(120, activation=\\'relu\\'))\\nmodel.add(Dense(10, activation=\\'softmax\\'))\\n\\nadam = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=\"adam\", metrics=[\\'accuracy\\'])\\n#model.load_weights(\\'.//training_B/checkpoints-weights.02-0.967273.hdf5\\')\\nmodel.fit(train, test, validation_split=0.33,epochs=7, batch_size=64)#, callbacks=[ckpt.tf_modelCkpt()])\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# TODO: ckpt.py file content has some error, may produce too many files but it can not got any one before use\n",
    "# need to check design is correct\n",
    "# training test when checkpoint is added\n",
    "import sys, subprocess, os, signal\n",
    "#import platform components\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Conv2D, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from csv_loader import dy_checkpoint, csv_loader\n",
    "from file_correctness import correct_model, correct_data, clear_path, correctness\n",
    "from checkpoint import ckpt, ckpt_create\n",
    "from recover_system_status import rss_initial, rss\n",
    "#from environment_detector import envir_daemon, start_daemon, env_initial\n",
    "#import custckpt\n",
    "\n",
    "def datapreprocess(data_train, x_test):\n",
    "    n_samples_test = x_test.shape[0]\n",
    "    y_train = np.array(data_train[:, 0])\n",
    "    x_train = np.array(data_train[:, 1:])\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "# make sure process is not duplicate\n",
    "pid = os.getpid()\n",
    "with open(\"train_pid.txt\", \"w\") as wf:\n",
    "\twf.write(\"tradinPID: \" + str(pid) + \"\\n\")\n",
    "\twf.close()\n",
    "# recieve user input and run file correctness check\n",
    "# start to read user input\n",
    "# dynamic loader\n",
    "train = csv_loader.CSVLoader(\"./data/cor/train.csv\")._dynamic_allocate()\n",
    "test = csv_loader.CSVLoader(\"./data/cor/test.csv\")._dynamic_allocate()\n",
    "train, test = datapreprocess(train, test)\n",
    "# model part\n",
    "# test comment\n",
    "# test comment\n",
    "#testtemp\n",
    "model = Sequential()\n",
    "model.add(Reshape(target_shape=(1, 28, 28), input_shape=(784,)))\n",
    "model.add(Conv2D(kernel_size=(3, 3), filters=6, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "model.add(Conv2D(kernel_size=(5, 5), filters=16, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "model.add(Conv2D(kernel_size=(5, 5), filters=120, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "#model.load_weights('.//training_B/checkpoints-weights.02-0.967273.hdf5')\n",
    "model.fit(train, test, validation_split=0.33,epochs=7, batch_size=64)#, callbacks=[ckpt.tf_modelCkpt()])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ckpt.py file content has some error, may produce too many files but it can not got any one before use\n",
    "# need to check design is correct\n",
    "# training test when checkpoint is added\n",
    "import sys, subprocess, os, signal\n",
    "#import platform components\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Conv2D, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from csv_loader import dy_checkpoint, csv_loader\n",
    "from file_correctness import correct_model, correct_data, clear_path, correctness\n",
    "from checkpoint import ckpt, ckpt_create\n",
    "from recover_system_status import rss_initial, rss\n",
    "from environment_detector import envir_daemon, start_daemon, env_initial\n",
    "#import custckpt\n",
    "\n",
    "def datapreprocess(data_train, x_test):\n",
    "    #n_samples_test = x_test.shape[0]\n",
    "    y_train = np.array(data_train[:, 0])\n",
    "    x_train = np.array(data_train[:, 1:])\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = csv_loader.CSVLoader(\"./data/cor/train.csv\")._dynamic_allocate()\n",
    "test = csv_loader.CSVLoader(\"./data/cor/test.csv\")._dynamic_allocate()\n",
    "#train, test = datapreprocess(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = tf.keras.utils.to_categorical(np.array(train[:, 0]), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = train[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44999, 784)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ba71f6aa4f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#model.load_weights('.//training_B/checkpoints-weights.02-0.967273.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/rtes/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape(target_shape=(1, 28, 28), input_shape=(784,)))\n",
    "model.add(Conv2D(kernel_size=(3, 3), filters=6, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "model.add(Conv2D(kernel_size=(5, 5), filters=16, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "model.add(Conv2D(kernel_size=(5, 5), filters=120, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#model.load_weights('.//training_B/checkpoints-weights.02-0.967273.hdf5')\n",
    "model.fit(train, test2,epochs=7, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个简单的序列模型\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 创建一个基本的模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 显示模型的结构\n",
    "model.summary()\n",
    "\n",
    "checkpoint_path = \"./tmp/training_A/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 创建一个保存模型权重的回调\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_weights_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "# 使用新的回调训练模型\n",
    "model.fit(train, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # 通过回调训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44999, 785)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 785)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6,\n",
       "       6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2,\n",
       "       3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4,\n",
       "       6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3,\n",
       "       6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4,\n",
       "       8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6,\n",
       "       5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1, 7, 1, 8, 2, 0, 2, 9, 9, 5, 5,\n",
       "       1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5, 1, 4, 4, 7, 2, 3, 2, 7,\n",
       "       1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1, 0, 9, 0, 3, 1, 6,\n",
       "       4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 9, 4, 5, 9, 3, 9, 0, 3, 6, 5, 5,\n",
       "       7, 2, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1, 5, 9,\n",
       "       8, 7, 2, 3, 0, 4, 4, 2, 4, 1, 9, 5, 7, 7, 2, 8, 2, 6, 8, 5, 7, 7,\n",
       "       9, 1, 8, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2,\n",
       "       6, 4, 1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2, 4, 0, 2, 7,\n",
       "       4, 3, 3, 0, 0, 3, 1, 9, 6, 5, 2, 5, 9, 2, 9, 3, 0, 4, 2, 0, 7, 1,\n",
       "       1, 2, 1, 5, 3, 3, 9, 7, 8, 6, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5,\n",
       "       5, 6, 1, 8, 5, 1, 7, 9, 4, 6, 2, 2, 5, 0, 6, 5, 6, 3, 7, 2, 0, 8,\n",
       "       8, 5, 4, 1, 1, 4, 0, 3, 3, 7, 6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5,\n",
       "       2, 5, 4, 4, 2, 8, 3, 8, 2, 4, 5, 0, 3, 1, 7, 7, 5, 7, 9, 7, 1, 9,\n",
       "       2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8, 4, 5, 9, 8, 8, 3, 7, 6,\n",
       "       0, 0, 3, 0, 2, 6, 6, 4, 9, 3, 3, 3, 2, 3, 9, 1, 2, 6, 8, 0, 5, 6,\n",
       "       6, 6, 3, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9, 1, 9, 7, 5,\n",
       "       4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 8, 9, 4, 0, 6, 3, 9, 5, 2, 1, 3,\n",
       "       1, 3, 6, 5, 7, 4, 2, 2, 6, 3, 2, 6, 5, 4, 8, 9, 7, 1, 3, 0, 3, 8,\n",
       "       3, 1, 9, 3, 4, 4, 6, 4, 2, 1, 8, 2, 5, 4, 8, 8, 4, 0, 0, 2, 3, 2,\n",
       "       7, 7, 0, 8, 7, 4, 4, 7, 9, 6, 9, 0, 9, 8, 0, 4, 6, 0, 6, 3, 5, 4,\n",
       "       8, 3, 3, 9, 3, 3, 3, 7, 8, 0, 8, 2, 1, 7, 0, 6, 5, 4, 3, 8, 0, 9,\n",
       "       6, 3, 8, 0, 9, 9, 6, 8, 6, 8, 5, 7, 8, 6, 0, 2, 4, 0, 2, 2, 3, 1,\n",
       "       9, 7, 5, 1, 0, 8, 4, 6, 2, 6, 7, 9, 3, 2, 9, 8, 2, 2, 9, 2, 7, 3,\n",
       "       5, 9, 1, 8, 0, 2, 0, 5, 2, 1, 3, 7, 6, 7, 1, 2, 5, 8, 0, 3, 7, 2,\n",
       "       4, 0, 9, 1, 8, 6, 7, 7, 4, 3, 4, 9, 1, 9, 5, 1, 7, 3, 9, 7, 6, 9,\n",
       "       1, 3, 7, 8, 3, 3, 6, 7, 2, 8, 5, 8, 5, 1, 1, 4, 4, 3, 1, 0, 7, 7,\n",
       "       0, 7, 9, 4, 4, 8, 5, 5, 4, 0, 8, 2, 1, 0, 8, 4, 5, 0, 4, 0, 6, 1,\n",
       "       7, 3, 2, 6, 7, 2, 6, 9, 3, 1, 4, 6, 2, 5, 4, 2, 0, 6, 2, 1, 7, 3,\n",
       "       4, 1, 0, 5, 4, 3, 1, 1, 7, 4, 9, 9, 4, 8, 4, 0, 2, 4, 5, 1, 1, 6,\n",
       "       4, 7, 1, 9, 4, 2, 4, 1, 5, 5, 3, 8, 3, 1, 4, 5, 6, 8, 9, 4, 1, 5,\n",
       "       3, 8, 0, 3, 2, 5, 1, 2, 8, 3, 4, 4, 0, 8, 8, 3, 3, 1, 7, 3, 5, 9,\n",
       "       6, 3, 2, 6, 1, 3, 6, 0, 7, 2, 1, 7, 1, 4, 2, 4, 2, 1, 7, 9, 6, 1,\n",
       "       1, 2, 4, 8, 1, 7, 7, 4, 8, 0, 7, 3, 1, 3, 1, 0, 7, 7, 0, 3, 5, 5,\n",
       "       2, 7, 6, 6, 9, 2, 8, 3, 5, 2, 2, 5, 6, 0, 8, 2, 9, 2, 8, 8, 8, 8,\n",
       "       7, 4, 9, 3, 0, 6, 6, 3, 2, 1, 3, 2, 2, 9, 3, 0, 0, 5, 7, 8, 1, 4,\n",
       "       4, 6, 0, 2, 9, 1, 4, 7, 4, 7, 3, 9, 8, 8, 4, 7, 1, 2, 1, 2, 2, 3,\n",
       "       2, 3, 2, 3, 9, 1, 7, 4, 0, 3, 5, 5, 8, 6, 3, 2, 6, 7, 6, 6, 3, 2,\n",
       "       7, 8, 1, 1, 7, 5, 6, 4, 9, 5, 1, 3, 3, 4, 7, 8, 9, 1, 1, 6, 9, 1,\n",
       "       4, 4, 5, 4, 0, 6, 2, 2, 3, 1, 5, 1, 2, 0, 3, 8, 1, 2, 6, 7, 1, 6,\n",
       "       2, 3, 9, 0, 1, 2, 2, 0, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 1.5215 - accuracy: 0.5295\n",
      "Epoch 00001: saving model to ./tmp/training_A/\n",
      "0\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1899 - accuracy: 0.6410 - val_loss: 0.7376 - val_accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "15/32 [=============>................] - ETA: 0s - loss: 0.4899 - accuracy: 0.8771\n",
      "Epoch 00002: saving model to ./tmp/training_A/\n",
      "1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8820 - val_loss: 0.5487 - val_accuracy: 0.8320\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2881 - accuracy: 0.9230\n",
      "Epoch 00003: saving model to ./tmp/training_A/\n",
      "2\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.9230 - val_loss: 0.5058 - val_accuracy: 0.8370\n",
      "Epoch 4/10\n",
      "16/32 [==============>...............] - ETA: 0s - loss: 0.2071 - accuracy: 0.9492\n",
      "Epoch 00004: saving model to ./tmp/training_A/\n",
      "3\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9500 - val_loss: 0.4573 - val_accuracy: 0.8460\n",
      "Epoch 5/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.1576 - accuracy: 0.9708\n",
      "Epoch 00005: saving model to ./tmp/training_A/\n",
      "4\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1546 - accuracy: 0.9720 - val_loss: 0.4562 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.1311 - accuracy: 0.9670\n",
      "Epoch 00006: saving model to ./tmp/training_A/\n",
      "5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1181 - accuracy: 0.9760 - val_loss: 0.4297 - val_accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.0811 - accuracy: 0.9883\n",
      "Epoch 00007: saving model to ./tmp/training_A/\n",
      "6\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0857 - accuracy: 0.9860 - val_loss: 0.4250 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9889\n",
      "Epoch 00008: saving model to ./tmp/training_A/\n",
      "7\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.9890 - val_loss: 0.4329 - val_accuracy: 0.8660\n",
      "Epoch 9/10\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.0495 - accuracy: 0.9944\n",
      "Epoch 00009: saving model to ./tmp/training_A/\n",
      "8\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9950 - val_loss: 0.4067 - val_accuracy: 0.8660\n",
      "Epoch 10/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9990\n",
      "Epoch 00010: saving model to ./tmp/training_A/\n",
      "9\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9990 - val_loss: 0.4192 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f16b0260048>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use mormal data to test checkpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from custckpt import ModelCheckpoint\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "\n",
    "# 定义一个简单的序列模型\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 创建一个基本的模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 显示模型的结构\n",
    "model.summary()\n",
    "\n",
    "checkpoint_path = \"./tmp/training_A/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 创建一个保存模型权重的回调\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_weights_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "# 使用新的回调训练模型\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # 通过回调训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import custckpt #import ModelCheckpoint\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registration...\n",
      "\n",
      "registration...\n",
      "\n",
      "● envir_daemon.service - envir_daemon\n",
      "   Loaded: loaded (/lib/systemd/system/envir_daemon.service; enabled; vendor preset: enabled)\n",
      "   Active: active (running) since Mon 2020-12-21 14:26:24 CST; 1 weeks 3 days ago\n",
      " Main PID: 19958 (python3)\n",
      "    Tasks: 2 (limit: 4915)\n",
      "   CGroup: /system.slice/envir_daemon.service\n",
      "           └─19958 /usr/bin/python3 /home/rtes/Desktop/demo/envir_daemon.py\n",
      "\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Charger isn't plugged!\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Fri Jan  1 13:18:52 2021:Daemon process is running...\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: System Busy\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Charger isn't plugged!\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Fri Jan  1 13:19:03 2021:Daemon process is running...\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: System Busy\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Charger isn't plugged!\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Fri Jan  1 13:19:14 2021:Daemon process is running...\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: System Busy\n",
      " 一  01 13:19:25 rtes-ThinkPad-X1-Carbon-5th python3[19958]: Charger isn't plugged!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training test when checkpoint is added\n",
    "import sys, subprocess, os, signal\n",
    "#import platform components\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from csv_loader import dy_checkpoint, csv_loader\n",
    "from file_correctness import correct_model, correct_data, clear_path, correctness\n",
    "from checkpoint import ckpt, ckpt_create\n",
    "from recover_system_status import rss_initial, rss\n",
    "from environment_detector import envir_daemon, start_daemon, env_initial\n",
    "import custckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = csv_loader.CSVLoader(\"./data/cor/train.csv\")._dynamic_allocate()\n",
    "test = csv_loader.CSVLoader(\"./data/cor/test.csv\")._dynamic_allocate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '0', '0', ..., '0', '0', '0'],\n",
       "       ['0', '0', '0', ..., '0', '0', '0'],\n",
       "       ['4', '0', '0', ..., '0', '0', '0'],\n",
       "       ...,\n",
       "       ['1', '0', '0', ..., '0', '0', '0'],\n",
       "       ['8', '0', '0', ..., '0', '0', '0'],\n",
       "       ['4', '0', '0', ..., '0', '0', '0']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '18',\n",
       "        '18', '18', '126', '136', '175', '26', '166', '255', '247',\n",
       "        '127', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '30', '36', '94', '154', '170', '253', '253', '253', '253',\n",
       "        '253', '225', '172', '253', '242', '195', '64', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '49', '238', '253',\n",
       "        '253', '253', '253', '253', '253', '253', '253', '251', '93',\n",
       "        '82', '82', '56', '39', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '18', '219', '253', '253', '253', '253',\n",
       "        '253', '198', '182', '247', '241', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '80',\n",
       "        '156', '107', '253', '253', '205', '11', '0', '43', '154', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '14', '1', '154', '253', '90', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '139', '253',\n",
       "        '190', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '11', '190', '253', '70', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '35', '241', '225', '160', '108', '1',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '81', '240',\n",
       "        '253', '253', '119', '25', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '45', '186', '253', '253', '150', '27', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '16', '93', '252', '253',\n",
       "        '187', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '249', '253', '249', '64', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '46', '130', '183', '253', '253', '207', '2', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '39', '148', '229', '253', '253', '253',\n",
       "        '250', '182', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '24', '114', '221',\n",
       "        '253', '253', '253', '253', '201', '78', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '23',\n",
       "        '66', '213', '253', '253', '253', '253', '198', '81', '2', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '18', '171', '219', '253', '253', '253', '253', '195',\n",
       "        '80', '9', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '55', '172', '226', '253', '253', '253',\n",
       "        '253', '244', '133', '11', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '136',\n",
       "        '253', '253', '253', '212', '135', '132', '16', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "        '0', '0', '0', '0', '0', '0']], dtype='<U3')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个简单的序列模型\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 1.4956 - accuracy: 0.5920\n",
      "Epoch 00001: saving model to ./tmp/training_A/\n",
      "0\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1672 - accuracy: 0.6700 - val_loss: 0.7205 - val_accuracy: 0.7970\n",
      "Epoch 2/10\n",
      "17/32 [==============>...............] - ETA: 0s - loss: 0.4783 - accuracy: 0.8676\n",
      "Epoch 00002: saving model to ./tmp/training_A/\n",
      "1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8830 - val_loss: 0.5556 - val_accuracy: 0.8310\n",
      "Epoch 3/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.2950 - accuracy: 0.9146\n",
      "Epoch 00003: saving model to ./tmp/training_A/\n",
      "2\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2915 - accuracy: 0.9170 - val_loss: 0.4533 - val_accuracy: 0.8580\n",
      "Epoch 4/10\n",
      "15/32 [=============>................] - ETA: 0s - loss: 0.1795 - accuracy: 0.9583\n",
      "Epoch 00004: saving model to ./tmp/training_A/\n",
      "3\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9500 - val_loss: 0.4610 - val_accuracy: 0.8440\n",
      "Epoch 5/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.1391 - accuracy: 0.9740\n",
      "Epoch 00005: saving model to ./tmp/training_A/\n",
      "4\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9660 - val_loss: 0.4469 - val_accuracy: 0.8520\n",
      "Epoch 6/10\n",
      "19/32 [================>.............] - ETA: 0s - loss: 0.1128 - accuracy: 0.9720\n",
      "Epoch 00006: saving model to ./tmp/training_A/\n",
      "5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9780 - val_loss: 0.4338 - val_accuracy: 0.8570\n",
      "Epoch 7/10\n",
      "19/32 [================>.............] - ETA: 0s - loss: 0.0843 - accuracy: 0.9836\n",
      "Epoch 00007: saving model to ./tmp/training_A/\n",
      "6\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9810 - val_loss: 0.4054 - val_accuracy: 0.8720\n",
      "Epoch 8/10\n",
      "19/32 [================>.............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9967\n",
      "Epoch 00008: saving model to ./tmp/training_A/\n",
      "7\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9970 - val_loss: 0.4135 - val_accuracy: 0.8670\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9990\n",
      "Epoch 00009: saving model to ./tmp/training_A/\n",
      "8\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 0.9990 - val_loss: 0.4060 - val_accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.0446 - accuracy: 0.9983\n",
      "Epoch 00010: saving model to ./tmp/training_A/\n",
      "9\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9990 - val_loss: 0.4201 - val_accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f67b6c05588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个基本的模型实例\n",
    "model = create_model()\n",
    "\n",
    "# 显示模型的结构\n",
    "model.summary()\n",
    "\n",
    "checkpoint_path = \"./records/ckpt_A/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 创建一个保存模型权重的回调\n",
    "cp_callback = custckpt.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_weights_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "# 使用新的回调训练模型\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # 通过回调训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "# import correctness_check\n",
    "# list file path and do correctness check\n",
    "# move uncorrect file to TEMP\n",
    "# searching DATA File\n",
    "# checkDATA renew\n",
    "# read file that content \"DONE\"\n",
    "\n",
    "def shuffle_split(infilename, outfilename1, outfilename2):\n",
    "    from random import shuffle\n",
    "\n",
    "    with open(infilename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # append a newline in case the last line didn't end with one\n",
    "    lines[-1] = lines[-1].rstrip('\\n') + '\\n'\n",
    "    traingdata = len(lines)* 75 // 100\n",
    "    print(traingdata)\n",
    "    testdata = len(lines)- traingdata - 1\n",
    "    print(testdata)\n",
    "    with open(outfilename1, 'w') as f:\n",
    "        f.writelines(lines[0:traingdata])\n",
    "    with open(outfilename2, 'w') as f:\n",
    "        f.writelines(lines[traingdata:])\n",
    "\n",
    "def checkDATA():\n",
    "\tdata_path = \"./data/\"\n",
    "\tcor_path = data_path + \"cor/\"\n",
    "\tif len(os.listdir(data_path)) == 0:\n",
    "\t\tprint(\"data path is empty!\\n\")\n",
    "\t\tsys.exit(0)\n",
    "\tdata_list = os.listdir(data_path)\n",
    "\tfor elements in range(len(data_list)):\n",
    "\t\tif data_list[elements] == \"cor\":\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\twith open(data_path + data_list[elements], \"r\") as df:\n",
    "\t\t\t\tfirstline = len(df.readline().split(\",\"))\n",
    "\t\t\t\tsecondline = len(df.readline().split(\",\"))\n",
    "\t\t\t\tif secondline > firstline:\n",
    "\t\t\t\t\tprint(\"data formate uncorrect!\\n\")\n",
    "\t\t\t\t\tsys.exit(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tshutil.copyfile(data_path + data_list[elements], cor_path + data_list[elements])\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\n",
    "\t# bubble sort\n",
    "\tdata_list = os.listdir(cor_path)\n",
    "\t# COR filepath only exist 2 correct data file\n",
    "\tif len(data_list) > 1:\n",
    "\t\tfor elements in range(len(data_list) - 1):\n",
    "\t\t\tvar1 = cor_path + data_list[elements]\n",
    "\t\t\tvar2 = cor_path + data_list[elements + 1]\n",
    "\t\t\tif os.path.exists(var1) and os.path.exists(var2) == True:\n",
    "\t\t\t\ttime1 = os.path.getctime(var1) // 1000\n",
    "\t\t\t\ttime2 = os.path.getctime(var2) // 1000\n",
    "\t\t\t\tif time1 > time2:\n",
    "\t\t\t\t\tos.remove(var2)\n",
    "\t\t\t\t\tshutil.move(var1, cor_path + \"data.csv\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tos.remove(var1)\n",
    "\t\t\t\t\tshutil.move(var2, cor_path + \"data.csv\")\n",
    "\t\n",
    "\tdata_list = os.listdir(cor_path)\n",
    "\tos.popen(\"mv \" + cor_path + data_list[0] + \" \" + cor_path + \"data.csv\")\n",
    "\tshuffle_split(cor_path + \"data.csv\", cor_path + \"train.csv\", cor_path + \"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "checkDATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv_loader import dy_checkpoint, csv_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = csv_loader.CSVLoader(\"./data/cor/train.csv\")._dynamic_allocate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44999, 785)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44999, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        0\n",
       "2        4\n",
       "3        1\n",
       "4        9\n",
       "        ..\n",
       "44994    1\n",
       "44995    9\n",
       "44996    1\n",
       "44997    8\n",
       "44998    4\n",
       "Name: label, Length: 44999, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = csv_loader.CSVLoader(\"./data/cor/test.csv\")._dynamic_allocate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        3\n",
       "2        1\n",
       "3        1\n",
       "4        5\n",
       "        ..\n",
       "14996    8\n",
       "14997    3\n",
       "14998    5\n",
       "14999    6\n",
       "15000    8\n",
       "Name: label, Length: 15001, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_correctness import correct_model, correct_data, clear_path, correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "correct_data.checkDATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15001 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label 1x1 1x2 1x3 1x4 1x5 1x6 1x7 1x8 1x9  ... 28x19 28x20 28x21 28x22  \\\n",
       "0         5   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "1         3   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "2         1   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "3         1   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "4         5   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "...     ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...   ...   ...   ...   ...   \n",
       "14996     8   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "14997     3   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "14998     5   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "14999     6   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "15000     8   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "\n",
       "      28x23 28x24 28x25 28x26 28x27 28x28  \n",
       "0         0     0     0     0     0     0  \n",
       "1         0     0     0     0     0     0  \n",
       "2         0     0     0     0     0     0  \n",
       "3         0     0     0     0     0     0  \n",
       "4         0     0     0     0     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...  \n",
       "14996     0     0     0     0     0     0  \n",
       "14997     0     0     0     0     0     0  \n",
       "14998     0     0     0     0     0     0  \n",
       "14999     0     0     0     0     0     0  \n",
       "15000     0     0     0     0     0     0  \n",
       "\n",
       "[15001 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = train.iloc[:, 1:]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train.label\n",
    "test_label = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test.drop(columns=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.values.reshape(test_image.shape[0], 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = tf.convert_to_tensor(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  method to show given number images.\n",
    "def show_img(img_vector_arr, label_tensor):\n",
    "    for i in range(len(img_vector_arr)):\n",
    "        plt.subplot(290 + (i+1))\n",
    "        plt.imshow(img_vector_arr[i],cmap=plt.get_cmap('gray'))\n",
    "        if label_tensor is not None:\n",
    "            plt.title(int(label_tensor[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e70b67430630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  just show initial few number images and label to see the kind of data we have in training dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "#  just show initial few number images and label to see the kind of data we have in training dataset.\n",
    "train_image = train_image.values.reshape(train_image.shape[0], 28, 28)\n",
    "train_image = tf.convert_to_tensor(train_image)\n",
    "# passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAABOCAYAAABL9HjJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAXO0lEQVR4nO2de3RU5d3vP7+ZzAQmV3KFQEiAcDEESFPAS6iAAZWA8FqB9VIptF20tcX6vge1rW97VqvtKQt7TmmXvspqfW1QQa0IVuCoC1QsCoQQQiK33AghcEiAhJDrZGYyv/PHJDFykVzmEvruz1rPYmbvzPN82TPf/Tz79/yevUVVMTAw8A+mQAswMPjvhGE4AwM/YhjOwMCPGIYzMPAjhuEMDPyIYTgDAz9iGM7AwI/cEoYTkT0iYheRpo5SHGhNACISJSLbRKRZRCpF5FuB1tSJiIztOGavBVoLgIg8KiKHRKRNRHICracTEblNRD4SkSsiUiYiD/qyvVvCcB08qqqhHWV8oMV08J+AA4gHHgZeFJGJgZXUxX8CeYEW0Y3/B/wWeDnQQjoRkSDg78AOIAr4AfCaiIzzVZu3kuEGFCISAjwE/E9VbVLVT4F3gW8HVhmIyL8C9cCHgdbSiapuVdV3gNpAa+nGBCABWK+q7ar6EfAZPvwObyXDrRWRSyLymYjMCrQYYBzgUtWSbtsKgYD2cCISDjwDrAmkjlsYAdJ8VfmtYrifAaOB4cCfge0iMiawkggFGq7adgUIC4CW7vwG+C9VPRtgHbcCxcAF4EkRsYjIvcBMwOarBm8Jw6lqrqo2qmqbqm7E0+1nB1hWExB+1bZwoDEAWgAQkXRgDrA+UBpuJVTVCfwLMB+oBh4H/gb47GQV5KuKfYzi6foDSQkQJCJjVbW0Y9sU4FgANc0CkoEzIgKeXtgsIqmqmhFAXQMWVS3C06sBICL7gI2+am/A93AiEiki94nIIBEJEpGHgbuB9wOpS1Wbga3AMyISIiKZwCLg1QDK+jMwBkjvKBuAncB9AdQEeCKCIjIIMOM5CQzqiBIGWtfkDi02EXkCGAbk+Kq9AW84wIInnHwRuAT8BPiXq4IVgeLHwGA81wGvAz9S1YD1cKraoqrVnQXPsNeuqhcDpakbvwRagZ8Dyzte/zKgijx8GziP5zvMAuaqapuvGhNjAaqBgf+4FXo4A4N/GgzDGRj4kX4ZTkTuF5Hijhy0n3tLVH8xdPUOQ5cfUdU+FTzRpnI8E9JWPFkWqX2tz1vF0GXoGsilz0ETEbkT+LWq3tfx/qkOA6/9is8EOkJzSVVjr94YaF2qet05RUPX9bnVdHWnP/Mgw4Gqbu/PArdf/Uci8gM8WdgDgcrOFwNMVxeGrt4xUHXdiP70cIuB+1V1Vcf7bwO3q+qjX/GZQPdw+ao69eqNgdZ1q52xDV3Xpyc9XH+CJueAxG7vR3RsMzAwuAH9GVLmAWNFZBQeo/0rMGBWPPub6OhoUlJSGDVqFAAVFRWUlpZSV1cXYGUGA4k+G05VXSLyKPABnojSy+rDtKagoC+kRkdHExwcTFBQEG63m+rqakaOHElMTAxut5vTp09TU1NDX4fLvcVmszFnzhyys7OZOXMmqsonn3zCjh072LJli1809AYRITw8nLFjx3Ly5EmampoCqickJIT4+Hji4uIAOH78OI2NjX77/vyKn0O9erNiMpnUbDar1WpVm82m4eHhGh0drePGjesqTzzxhK5fv15zcnL0ueee04yMDN22bZu63W5tbGzU5557TtPT069X/6G+6rpRsVgsOnPmTK2srFSHw6Eul0udTqfa7XYtKSnRoKCgm9bR0+NlMpnUYrGo1Wrts15ArVarzps3T6uqqnT69Ok6aNCgfunq7/GbMWOGvvLKK9re3q7t7e06a9YstVgs/T5e/i498UDAs7WvZvjw4QQHBzN27FimTJnC+PHjiY6OZv78+df8bVNTE2fOnCEpKYns7GwaGxs5evQoBw4coKamxudaLRYLX//613n11VcZNmwYJpOJlpYW2to8ua9RUVFMnz6d/Pz8rm39IT4+ntTUVKxWK++9916f6wkKCiI9PZ0jR47gcrn6ras/TJs2je9+97ssXrz4avP4FRGhY0kTwDUavKVpQBkuPT2dt99+m+HDh3cNIbsfhO6oKgcPHiQnJwe73c7GjRs5f/48dXV1VFZW0tra6jOdQUFBDBkyhKlTp/LCCy+QkJDQpfPixYt8+OGHnD59mqeffpo9e/bwq1/9ij/+8Y/91pSQkEBWVhZhYWH9MpzFYiE5OZmkpCRMpsBm90VFRREbG4vFYglI+6GhoWRkZLBkyRK+8Y1vMGHCBMxmM1u2bOGjjz5CVRk/fjxvvfUWBw8e7Hd7A8pwZ8+epb6+nmHDhl3XaIcPH6ahoYHJkydjs9k4ceIEW7Zs6Tr7uN1uVJX29naf6rzjjjt47LHHmDNnDqGhoV/aN2LECJKSkigtLeXQoUNMmzaN1NTUL12D9pWUlBSysrI4dOhQn+uwWCwkJiayfPly3n33XcrKyrDb7f3W1hfS09NZunQpmZmZ2O12jh07xiOPPEJZWZlfet7k5GQWLVrET37yE+Lj4wkODiY/P5+QkBBmzpzJvHnzAGhvbycqKoq8vLx+93QDynCXL19mw4YN3H333bS2tpKcnExWVhbt7e2UlZXxox/9iKamJsaOHcvdd99NaWmpV4ZqvWHo0KFMmzaNzMxMIiIiACgoKCA3N5cHH3yQkJAQqqurOXz4MG63m+nTp2O1Wr3StslkYtCgQf2qIzExkTVr1jBo0CAqKipwOBxe0dZbJk6cyJo1a5g9ezZhYWFUVVWxadMmjh8/jtPp9Omw0mQykZCQwKJFi1i9ejXx8fGcPHmSnJwc9u/fj8lkYtmyZSxatIhRo0bR3NxMZWXlzSvuAQPKcO3t7bz//vsUFxdjt9vJyMggNjaWlJQU3nnnHQoLC3E6nZw7d45Tp0753WxxcXEsXbqUJUuWEB0djcvl4vjx46xduxar1YrVaqW6uppPPvmEwsJCLl++DMCkSZNISkqipKSkzz/wyMhIhg4dSkhISL/+D4MHD2bChAmA50QRqGu42bNnM336dOLi4mhsbKSwsJCdO3f65QSQlpbGQw89xIIFC4iLi+PYsWP8/ve/Z//+/dTU1JCWlkZUVBSRkZG4XC4uXrzI7t27vXISGFCGA6iqqqKmpob29nasVivl5eWkpKTgdDq7fhyNjY0cO+bfhdXh4eHccccdLFiwgClTpuBwOKivr2f37t3s3LmT5ORkqqurqaqqoqqqira2NkQEVWXUqFHMnj2bmpoaLl7s2+LrkSNHMnr0aGy2vt9Qymw2ExoaSlRUFKpKcXGxz4ff12PQoEHcd999DB06FIDy8nI+/PBDTp065fO209PTu3qv6Oho8vLy2Lp1Kzt37uwaWs+aNYuMjAwiIyOpra1l165dFBUVeaX9AbkezuFw0N7eTn19PRUVFbS1tZGdnU1UVNQNgyi+RETIyMjgm9/8JuPHj6euro68vDx27drFrl27sNvtnDx5ko8//piysrJrel6LxcK9997bNQTtC8nJySQnJyMifQ6+REdHc9tttxEbG0trayt1dXV+jwgGBwczdepUMjMzCQ0N5cKFC+zfv5/du3f7vO0RI0bw/e9/n5UrV5KQkEBBQQE5OTldgTcRITIykqysLJKTk2lubqaoqIi//vWvXpurHHA9XHdOnjzJpk2bSEtLY86cOdxzzz189NFHtLa20tbW5rezs81mY/Xq1WRlZeF2u9m+fTsvvvgiZWVlBAcH96iO2NjYfl3LRUVFER0djd1up7y8vMefExEsFgtWq5U777yTFStWEBYWRmFhIU1NTX41nNlsZtSoUTz//POEhobidDr57LPP2LFjB8XFvn1chMlk4sc//jErVqwAPAG4119/nbfeeguHw4HZbCY2NpZZs2YxZswYLBYLhw4dYuPGjeTm5npPyECb+L66BAcH69SpU7W+vl7PnDmjmzdv1qeeekrT0tK0I1m1N6VPE9933XWX1tbWqsvl0nXr1mlKSkqP2ouLi1O3263t7e164MABTU1N7fNE7ne+8x3dt2+ffv755zpjxowbtikiXcVkMmlERITef//9+oc//EELCgrU4XBofX29Llu2rM8TuX35HgG12Wy6evVqdTgc2t7ervv27dMHH3zwhhPv3tIlIhoVFaXnz59Xp9Ope/bs0blz53bts1gsOmHCBD1w4IDa7XZ1uVx68OBBfeSRR3ql7Zac+L6atrY2Pv/8c1atWsVf/vIXli5dytKlS8nIyGDTpk3s3buX2lrf3a7eZDKxbt06QkNDOXLkCHv37qWsrKzHn+8cAntrKGyxWBgyZMiXtqWkpBASEkJiYiKTJk0iLi6O4OBgli1bhslkwuFwcOrUKdxuN21tbTgcDgoKCryip6dERUUxf/58fvvb3yIi5Obm8tOf/pT8/Hy/TEtYrVaio6MREdavX8/Ro0eZMWMGCxYsYObMmdx2222EhXlumq2q5Obmsm/fPq9rG/CGA4/ptm/fzgMPPMBTTz1FZmYmCxYsYOTIkYwaNYpNmzZx4cIFr7drtVq55557mDx5Mmazmf3791NVVXXzD3aj88x24sQJWlpa+qzF6XTidDpJSkriT3/6E2vWfPHogJSUFGw2GyaTCVWltbWV8vJy3njjDY4ePUp+fj7nzp1j4cKF/OY3v8HpdFJaWvoVrXmX0NBQMjMzef755wkJCUFEqKqqorq62qcJCt1xOBzU1tYSExNDTk4OTqcTs9mM1WrFbDZTW1tLc3MzcXFxNDQ0kJ+f75PA3C1hOPCYLj8/n1/84hfMnDmT5cuXk5qayqpVq0hISODJJ5/0epsiQlhYGIMHD6a+vp5//OMfnDlz5qaf65znefjhh1FVDh06xAsvvNCvdLP333+f5uZmFi5cSHJy8pfC5+Xl5ZSVlVFSUsKZM2coLS3FbrfT1NREc3Mzzc3NpKamMnHiRIKDg6msrPRrdHL8+PE88MADXVMaqsrrr7/uk5Pk9VBVGhoaePLJJ1m7di3x8fE0NDRQWlrKwYMH+fTTT7l8+TLPPPMM0dHR5Obmcvr0aZ8co1vGcACtra0cO3aMuro6br/9dr72ta8xevRo5s6dy7hx4ygp8f69YU0mU1dksKqqioaGq5/fce3fjx49muzsbL71rW9RV1fH22+/zYkTJ/o1PKmtrWXv3r2cPXuWqKio6+6vra3lypUrXfN/3RkzZgzjxo2jpaWlX5kqvWXIkCFMmjSJadOmdQVoCgsLOXz4MM3NzX7T4XK5+OCDD3A6nYSGhtLW1kZtbS3nzp3j3LlzJCYmMnLkSMxmM5WVldTX1/tExy1luKioKJKTk4mJiekKsZtMph5HCvvD6dOnqa+v/8qzXkREBCkpKcyePZvs7GxMJhMbNmxgx44dtLS09Dsi2GmqvhAZGUlkZCRXrlzh008/7ZeO3nDXXXcxb948kpKSUFVqamrIycnhwoULfp8DvHjxIm+++eY12y0WC9HR0V3zgsXFxT6LCwx4w5lMJgYPHkx8fDzTpk1j9uzZjBs3jtTUVEQEu91OZWWlz69JqqurcTqdN9wfHx/P9OnTuffee7nzzjuxWq1s3ryZtWtveE+lgNDS0uLXpIG5c+eSnZ3NoEGDsNvt7N+/n5dffjlg+ZvXQ1Vpbm5GVRERTpw40ecEhZsxYA0nIgQFBREREUFaWhorVqxg3rx5xMbGIiK43W5aWlq4ePEip0+f9tl8UueyjczMTIYOHcrZs2e7Ml4sFkvXQtiVK1eycuVKEhMTOXXqFK+99hrPPvusTzT1F7PZ7Jd2bDYb4eHh2Gw2VBWHw8Gbb77Zr+CRL3C5XBw5cqTLcL5kwBouIiKCyZMns3DhQpYsWcKIESO69qkqlZWVfPDBB2zevJnPPvvMZzo6o4wxMTE89thjbNu2jaKiIkSEqVOnsnjxYiZPnkxCQgIXLlzg4MGD7N69mx07dvhMU38YPHgwSUlJ3p3MvQGPP/44M2bMwGQy4Xa7cblc5OUNpMeOe7BarcyePdsvWUwDznCxsbGMGTOG733ve8ybN4+EhIQv7T98+DAbN27kvffeo6KiArfb7RddJpOJhx56iDlz5nDlyhXAk3nf+SXl5+dz4MABXn31VfLz8wOyiLIn+OMsDp7VALNmzWLYsGG4XC7Onj3LK6+84rfIZG8wm82MHj3aL20NCMOJCEOGDOHZZ58lLS2NpKQkIiIiulKhXC4Xhw8fZsOGDXz88cdcunQJu93uc7M5nU7y8vIoKChgypQpmM1mIiIiCA8P7zJUXV0d77zzDk8//TT19fW0tbUNWLOBZ04sPT39usEDbxIWFkZMTAyDBw+mubmZgoIC1q1bN6Cu3TpxOp3k5ub6ZTHuTQ0nIonAK0A8nhSWP6vqn0Tk18D38Ty3DeA/VPX/9qbxIUOGMGXKFObPn8/EiROZNm0aNpuN4ODgruu08+fPs337dl566SUqKipoaGjwW3TL7XZz9uxZnnjiCZYsWcLixYuJi4tDRLh06RI7d+7k73//O4WFhZw/f95vvW1faGpq4oc//CENDQ03ndrwBmazuWtKRVVxuVwD7tqtE5fLxcmTJ6mqqiIhIYG4uDhCQkJ8cnLoSQ/nAh5X1cMiEgbki8iujn3rVfV/97XxYcOGkZWVxeLFi4mJicFms3HhwgWKi4u7Fv0dOHCAoqIijh49GpC1Ww6Hg7y8PK5cucK+ffu6Jm+bm5spLS2lpKTELz/g/lJTU8Py5ctZtmwZL730Er/8pW+fhVhTU0NFRQUjRowIyAqP3tLc3MzWrVtZtWoVc+fOpbq6moMHD3ZdPniLmxpOVc/jeUIkqtooIifw3Oa837S0tFBeXv6l+3PU1NRQUlJCS0sLVVVVHDt2zO8LTa+mtbWVwsJCCgsLA6qjP1RUVHDkyBEcDgf5+fk+b6+mpoa//e1vHD9+HKvVyvHjx33eZn9QVbZt28acOXO4/fbbuXTpEo2NjeTl5Xl3RNXLbP9k4AwQDvwaOA0UAS8DQ27wmR8AhzpKn7LMvVgODURdA/V4/XfTZbPZ9He/+50WFRVpfn6+/uxnP9OwsLA+6bqhh3phtlAgH/hmx/t4PDeANQH/C8+NYL2+PMfLxev3pfT2D8jQFVhdISEh+uijj+qePXt0w4YNmpiY2G9d3UuPHuYhIhZgB/CBqv7hOvuTgR2qmnaTem7emG8xHubRCwxdveNGurrTkyilAP8FnOhuNhEZ1nF9B/AgcLQHmi4BzR3/eoNkoJ0vPzbLAnTmYMUB0cCJjvdJN6inCfDmkuPe6LqRJkPXF7o6J8lO+VnXzYjhi9/yV+nq4qY9nIjMAPYCnwOdce//AJYB6Xi609PAD7sZ8KvqO3S9Xqa39EJXkqpO8YcmQ5fPdI0EbrvZ78ubunpCX9rrSZTyU+B6XWWv5ty8TU91iYj/1qJg6OotPdHV8cO+6cn8VmBA3rXLwOCflUAY7s8DsD1/a+ppm4au3rU3UHV10edHDhsYGPQeY0hpYOBHDMMZGPgRvxlORO4XkWIRKRORn/ug/kQR+VhEjovIMRH5t47tvxaRcyJypKNkG7oMXf7SdQ29yaXsa8GTAlaOZwLTChQCqV5uYxiQ0fE6DCgBUvHkfD5h6DJ0+VvX9Yq/erjpQJmqnlJVB/AGsMibDajqeVU93PG6EU+2xM1WNRi6DF2+1HUN/jLccL6ctnMWLy3xuR4duZ1fAzpv3PGoiBSJyMsi0v0+4YYuQ5cvdV3DP13QRERCgbeBf1fVBuBFYAyeNKHzwP8xdBm6AqXLX4Y7ByR2ez+iY5tX6VjV8DawSVW3Aqhqjaq2q6ob+Aue4Yehy9DlD13X4s0Ly6+44AzCk+k9ii8uaid6uQ3Bc++VP159sdvt9f8A3jB0Gbr8oeu69XhT1E0EZ+OJ7JQDv/BB/TPwZJYXAUc6SjbwKp5M9CLg3e4HyNBl6PK1rquLkdplYOBH/umCJgYGAxnDcAYGfsQwnIGBHzEMZ2DgRwzDGRj4EcNwBgZ+xDCcgYEf+f891SOvdzWNcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(train_image[0:5], train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hidden layer of RELU neuron\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with right optimizer, loss function and metric to optimize.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.5794 - accuracy: 0.9024\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.5194 - accuracy: 0.9480\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.5058 - accuracy: 0.9600\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4975 - accuracy: 0.9671\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4917 - accuracy: 0.9724\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4872 - accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4843 - accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4813 - accuracy: 0.9819\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4790 - accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 1.4779 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7d8d139b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with training dataset.\n",
    "model.fit(train_image, train_label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step\n",
    "# test all task can work perfectlly\n",
    "# especial checkpoint\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
